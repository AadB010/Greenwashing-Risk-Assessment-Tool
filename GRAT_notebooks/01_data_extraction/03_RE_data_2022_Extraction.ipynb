{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64c1761f",
   "metadata": {},
   "source": [
    "# Refinitiv Eikon Data 2022: Variable Extraction\n",
    "\n",
    "## Overview\n",
    "This module extracts environmental and financial variables from individual company Excel files exported from Refinitiv Eikon Datastream. The data was previously exported through the SUSFIN category at Erasmus University Rotterdam, with each company's ESG data saved as separate Excel files in the `/data/Eikon/ESG/` directory.\n",
    "\n",
    "## Data Source Structure  \n",
    "- **Source**: 27 individual Excel files (one per company) exported from Datastream\n",
    "- **Target sheet**: \"Environment\" tab within each company file\n",
    "- **Target year**: 2022 data specifically extracted from row 5\n",
    "- **Companies**: 14 sample companies plus 13 additional European utilities for sector comparison\n",
    "\n",
    "## Key Variables Extracted\n",
    "- **Temporal data**: Period end date for alignment verification\n",
    "- **Financial metrics**: Revenue calculations and energy costs per revenue  \n",
    "- **Energy data**: Total energy use, renewable energy ratios, and production figures\n",
    "- **Emission data**: Scope 1, 2, and 3 CO2 emissions with intensity metrics\n",
    "- **Target information**: Emission reduction targets and timelines\n",
    "- **Validation data**: ESG scores and auditor information for transparency assessment\n",
    "\n",
    "## Data Processing\n",
    "- Robust text matching for variable identification across different file formats\n",
    "- Revenue calculation from emission intensity ratios where direct revenue data unavailable\n",
    "- Column renaming for standardization and brevity\n",
    "- Final output saved as `Eikon_Final_2022.xlsx` with formatting optimizations\n",
    "\n",
    "## Note\n",
    "While comprehensive environmental data is extracted, the final analysis primarily uses emission intensity metrics and target information. Other variables serve as supporting data for validation and context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b37368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# List of companies to process\n",
    "companies = [\n",
    "    \"AKENERJİ ELEKTRİK ÜRETİM A.Ş.\",\n",
    "    \"Arendals Fossekompani ASA\",\n",
    "    \"Atlantica Sustainable Infrastructure PLC\",\n",
    "    \"CEZ\",\n",
    "    \"EDF\",\n",
    "    \"EDP - Energias de Portugal S.A.\",\n",
    "    \"Endesa\",\n",
    "    \"ERG S.p.A\",\n",
    "    \"Ørsted\",\n",
    "    \"Polska Grupa Energetyczna (PGE) SA\",\n",
    "    \"Romande Energie Holding SA\",\n",
    "    \"Scatec ASA\",\n",
    "    \"Solaria Energia y Medio Ambiente SA\",\n",
    "    \"Terna Energy S.A\",\n",
    "    \"A2A\",\n",
    "    \"Albioma\",\n",
    "    \"AYDEM YENİLENEBİLİR ENERJİ A.Ş.\",\n",
    "    \"ContourGlobal\",\n",
    "    \"Drax Group\",\n",
    "    \"EnBW Energie Baden-Württemberg AG\",\n",
    "    \"ENGIE\",\n",
    "    \"Fortum Oyj\",\n",
    "    \"MYTILINEOS Holdings S.A.\",\n",
    "    \"NEOEN SA\",\n",
    "    \"RWE AG\",\n",
    "    \"SSE\",\n",
    "    \"VERBUND AG\",\n",
    "]\n",
    "\n",
    "# Directory where the company files are stored\n",
    "base_dir = \"data/Eikon/ESG/\"\n",
    "\n",
    "## List of the variable names that we need to extract\n",
    "variables = [\n",
    "    \"Period End Date\", \"ESG Report Auditor Name\", \"ESG Combined Score\",\n",
    "    \"Resource Reduction Policy\", \"Resource Reduction Targets\", \n",
    "    \"Policy Energy Efficiency\", \" Targets Energy Efficiency\",\n",
    "    \"Policy Environmental Supply Chain\", \"Total Energy Use / Million in Revenue $\",\n",
    "    \"Energy Use Total\", \"Energy Purchased Direct\", \"Energy Produced Direct\",\n",
    "    \"Indirect Energy Use\", \"Electricity Purchased\", \"Electricity Produced\",\n",
    "    \"Renewable Energy Use Ratio\", \"Renewable Energy Supply\", \"Total Renewable Energy\",\n",
    "    \"Renewable Energy Purchased\", \"Renewable Energy Produced\",\n",
    "    \"Emission Reduction Target Percentage\", \"Emission Reduction Target Year\",\n",
    "    \"Estimated CO2 Equivalents Emission Total\", \"Total CO2 Emissions / Million in Revenue $\",\n",
    "    \"CO2 Equivalent Emissions Direct, Scope 1\", \"CO2 Equivalent Emissions Indirect, Scope 2\",\n",
    "    \"CO2 Equivalent Emissions Indirect, Scope 3\"\n",
    "]\n",
    "\n",
    "# Initialize an empty list to store each company's data\n",
    "all_companies_data = []\n",
    "\n",
    "# Loop through each company\n",
    "for company_name in companies:\n",
    "    # Construct the file path\n",
    "    file_path = os.path.join(base_dir, f\"{company_name}.xlsx\")\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found for company: {company_name}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Load the specific sheet 'Environment'\n",
    "    company_data = pd.read_excel(file_path, sheet_name=\"Environment\")\n",
    "\n",
    "    # Find the column that corresponds to the year 2022 (search for \"2022\" in row 5, which is index 3 in Python)\n",
    "    year_column = company_data.iloc[3].apply(lambda x: '2022' in str(x)).idxmax()  # Find the column with \"2022\" in row 5 (index 3 in Python)\n",
    "\n",
    "    # Create a dictionary to store company name and corresponding variable values\n",
    "    company_data_dict = {'Company Name': company_name}\n",
    "\n",
    "    # Loop through the variables and extract their values\n",
    "    for variable in variables:\n",
    "        try:\n",
    "            # ENHANCED: More robust text cleaning and searching\n",
    "            # Clean both the search term and the column data\n",
    "            clean_variable = variable.strip()\n",
    "            \n",
    "            # Clean Column B: strip whitespace and normalize internal spaces\n",
    "            cleaned_column_b = (company_data.iloc[:, 1]\n",
    "                              .str.strip()  # Remove leading/trailing spaces\n",
    "                              .str.replace(r'\\s+', ' ', regex=True))  # Normalize multiple spaces to single space\n",
    "            \n",
    "            # Try exact match first\n",
    "            exact_match = cleaned_column_b == clean_variable\n",
    "            if exact_match.any():\n",
    "                row_idx = company_data[exact_match].index[0]\n",
    "            else:\n",
    "                # Try contains match (case insensitive)\n",
    "                contains_match = cleaned_column_b.str.contains(clean_variable, na=False, case=False, regex=False)\n",
    "                if contains_match.any():\n",
    "                    row_idx = company_data[contains_match].index[0]\n",
    "                else:\n",
    "                    raise IndexError(\"Not found\")\n",
    "            \n",
    "            # Add the value to the dictionary\n",
    "            company_data_dict[variable] = company_data.iloc[row_idx][year_column]\n",
    "        \n",
    "        except IndexError:\n",
    "            company_data_dict[variable] = \"Not found\"\n",
    "            # Debug for the problematic variables\n",
    "            if variable in [\"Total Energy Use / Million in Revenue $\", \"Total CO2 Emissions / Million in Revenue $\"]:\n",
    "                print(f\"DEBUG - Could not find '{variable}' for {company_name}\")\n",
    "                # Show similar matches for debugging\n",
    "                similar = cleaned_column_b[cleaned_column_b.str.contains(\"Million in Revenue\", na=False, case=False)]\n",
    "                if len(similar) > 0:\n",
    "                    print(f\"  Similar matches found: {similar.tolist()[:3]}\")  # First 3 matches\n",
    "            company_data_dict[variable] = \"Not found\"\n",
    "\n",
    "    # Append the company data dictionary to the list\n",
    "    all_companies_data.append(company_data_dict)\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "companies_df = pd.DataFrame(all_companies_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "companies_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586742d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Store the original DataFrame to identify the deleted rows\n",
    "companies_df_original = companies_df.copy()\n",
    "\n",
    "# Replace '--' and 'Not found' with NaN in the entire dataframe\n",
    "companies_df.replace({'--': np.nan, 'Not found': np.nan}, inplace=True)\n",
    "\n",
    "# Identify the rows with NaN in the 'Period End Date' column\n",
    "deleted_rows = companies_df_original[companies_df_original['Period End Date'].isin([None, '0', '--'])]\n",
    "\n",
    "# Clean the dataset by removing rows with NaN in the 'Period End Date' column\n",
    "companies_df_cleaned = companies_df[\n",
    "    companies_df['Period End Date'].notna()  # Keep only rows where 'Period End Date' is not NaN\n",
    "]\n",
    "\n",
    "# Display the cleaned dataset\n",
    "companies_df_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cea87e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the deleted rows\n",
    "deleted_rows = companies_df[\n",
    "    companies_df['Period End Date'].isin([None, '0', '--']) | \n",
    "    companies_df['Period End Date'].isna()\n",
    "]\n",
    "\n",
    "# Print the deleted rows\n",
    "deleted_rows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c6b9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the \"Period End Date\" to remove the time part\n",
    "companies_df_cleaned['Period End Date'] = pd.to_datetime(companies_df_cleaned['Period End Date'], errors='coerce').dt.date\n",
    "\n",
    "# Rename columns to shorter names, preserving all important information and adding units in brackets\n",
    "companies_df_cleaned.rename(columns={\n",
    "    \"Company Name\": \"Organization\",\n",
    "    \"ESG Report Auditor Name\": \"ESG Auditor\",\n",
    "    \"ESG Combined Score\": \"ESG Score\",\n",
    "    \"Resource Reduction Policy\": \"Res. Red. Policy\",\n",
    "    \"Resource Reduction Targets\": \"Res. Red. Targets\",\n",
    "    \"Policy Energy Efficiency\": \"Energy Eff. Policy\",\n",
    "    \"Targets Energy Efficiency\": \"Energy Eff. Targets\",\n",
    "    \"Policy Environmental Supply Chain\": \"Env. Supply Chain Policy\",\n",
    "    \"Total Energy Use / Million in Revenue $\": \"Energy Use/Rev. (M$)\",\n",
    "    \"Energy Use Total\": \"Energy Use Tot.\",\n",
    "    \"Energy Purchased Direct\": \"Energy Purch. Dir.\",\n",
    "    \"Energy Produced Direct\": \"Energy Prod. Dir.\",\n",
    "    \"Indirect Energy Use\": \"Energy Use Ind.\",\n",
    "    \"Electricity Purchased\": \"Elec. Purchased\",\n",
    "    \"Electricity Produced\": \"Elec. Prod.\",\n",
    "    \"Renewable Energy Use Ratio\": \"Renew. Energy Use (%)\",\n",
    "    \"Renewable Energy Supply\": \"Renew. Energy Supply (%)\",\n",
    "    \"Total Renewable Energy\": \"Total Renewable Energy\",\n",
    "    \"Renewable Energy Purchased\": \"Renew. Energy Purch.\",\n",
    "    \"Renewable Energy Produced\": \"Renew. Energy Prod.\",\n",
    "    \"Emission Reduction Target Percentage\": \"Em. Red. Target (%)\",\n",
    "    \"Emission Reduction Target Year\": \"Em. Red. Target Year\",\n",
    "    \"Estimated CO2 Equivalents Emission Total\": \"Est. CO2 Em. Tot. (ton CO2e)\",\n",
    "    \"Total CO2 Emissions / Million in Revenue $\": \"CO2 Em. / Rev. (M$)\",\n",
    "    \"CO2 Equivalent Emissions Direct, Scope 1\": \"CO2 Em. Scope 1 (ton CO2e)\",\n",
    "    \"CO2 Equivalent Emissions Indirect, Scope 2\": \"CO2 Em. Scope 2 (ton CO2e)\",\n",
    "    \"CO2 Equivalent Emissions Indirect, Scope 3\": \"CO2 Em. Scope 3 (ton CO2e)\"\n",
    "}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53b6cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate 'Revenue (M$)' and add as a new column\n",
    "companies_df_cleaned['Revenue (M$)'] = (\n",
    "    companies_df_cleaned['CO2 Em. Scope 1 (ton CO2e)'].astype(float) +\n",
    "    companies_df_cleaned['CO2 Em. Scope 2 (ton CO2e)'].astype(float)\n",
    ") / companies_df_cleaned['CO2 Em. / Rev. (M$)'].astype(float)\n",
    "companies_df_cleaned['Revenue (M$)'] = companies_df_cleaned['Revenue (M$)'].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5caa732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Total Renewable Energy / Revenue\n",
    "companies_df_cleaned['Total Renewable Energy / Rev. (M$)'] = round(companies_df_cleaned['Total Renewable Energy'] / companies_df_cleaned['Revenue (M$)'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a0fdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output path\n",
    "output_path = \"data/Eikon/Eikon_Final_2022.xlsx\"\n",
    "\n",
    "# Save the cleaned DataFrame to an Excel file\n",
    "companies_df_cleaned.to_excel(output_path, index=False, engine=\"openpyxl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1facb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import Workbook\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.styles import PatternFill\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# Define file path and output path\n",
    "output_path = \"data/Eikon/Eikon_Final_2022.xlsx\"  # You can change this path if needed\n",
    "\n",
    "# Save the DataFrame to Excel\n",
    "companies_df_cleaned.to_excel(output_path, index=False, engine=\"openpyxl\")\n",
    "\n",
    "# Load the workbook and sheet\n",
    "wb = load_workbook(output_path)\n",
    "ws = wb.active  # There's only one sheet since we saved just one DataFrame\n",
    "\n",
    "# Auto-adjust column widths based on the longest string in each column\n",
    "for col in ws.columns:\n",
    "    max_length = 0\n",
    "    col_letter = get_column_letter(col[0].column)\n",
    "    for cell in col:\n",
    "        if cell.value:\n",
    "            max_length = max(max_length, len(str(cell.value)))\n",
    "    ws.column_dimensions[col_letter].width = max_length + 3  # Add padding\n",
    "\n",
    "# Define grey fill for alternating rows\n",
    "grey_fill = PatternFill(start_color=\"D9D9D9\", end_color=\"D9D9D9\", fill_type=\"solid\")\n",
    "\n",
    "# Alternate row colors by company\n",
    "prev_company = None\n",
    "use_grey = False\n",
    "for row in range(2, ws.max_row + 1):\n",
    "    current_company = ws[f\"A{row}\"].value  # Column A has the company names\n",
    "    if current_company != prev_company:\n",
    "        use_grey = not use_grey\n",
    "        prev_company = current_company\n",
    "\n",
    "    if use_grey:\n",
    "        for col in range(1, ws.max_column + 1):\n",
    "            ws.cell(row=row, column=col).fill = grey_fill\n",
    "\n",
    "# Save the final cleaned and formatted workbook\n",
    "wb.save(output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
