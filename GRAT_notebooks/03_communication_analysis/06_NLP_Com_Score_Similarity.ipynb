{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74f46d2e",
   "metadata": {},
   "source": [
    "# Cross-Year Document Similarity Analysis  \n",
    "\n",
    "## Overview\n",
    "This module measures reporting consistency by comparing sustainability reports across 2021 and 2022 to detect recycled content versus genuine annual updates. It employs multiple similarity methods to identify symbolic rather than substantive reporting patterns, directly supporting the Reporting Consistency dimension.\n",
    "\n",
    "## Multi-Method Similarity Assessment\n",
    "1. **TF-IDF Document Similarity**: Measures overall document similarity based on term frequency patterns\n",
    "2. **Jaccard Similarity**: Calculates shared vocabulary ratio as (common words ÷ total unique words) \n",
    "3. **Sentence-level SpaCy Analysis**: Semantic similarity using word vectors for individual sentence pairs\n",
    "\n",
    "## Sentence Matching Algorithm\n",
    "- **Content filtering**: Only sentences with 10+ meaningful words (excluding stopwords/punctuation)\n",
    "- **Greedy matching**: Each sentence from shorter document paired with best match from longer document\n",
    "- **Iterative process**: Highest similarity pairs selected first, matched sentences removed, process repeats\n",
    "- **Performance optimization**: Limits to 300 sentences per document for computational efficiency\n",
    "\n",
    "## High Similarity Detection\n",
    "- **Threshold**: 99.9% similarity for near-identical content detection\n",
    "- **Target patterns**: Minor changes like \"reduced emissions by 15% in 2021\" vs. \"reduced emissions by 15% in 2022\"\n",
    "- **Quality validation**: SpaCy's word vector similarity naturally assigns high scores to substantively similar content within same company contexts\n",
    "\n",
    "## Variables Produced for Communication Scoring\n",
    "According to the analysis framework:\n",
    "- **Cross-Year Similarity Score** → Reporting Consistency dimension\n",
    "- **High-Similarity Sentence Ratio** → Reporting Consistency dimension\n",
    "\n",
    "## Theoretical Foundation\n",
    "Based on research showing widespread boilerplate language in sustainability reports correlating with ESG rating problems. Distinguishes between legitimate annual updates and lazy content recycling that suggests symbolic compliance rather than substantive environmental progress.\n",
    "\n",
    "## Output Metrics\n",
    "- **High similarity ratio**: (sentences above 99.9% similarity) ÷ total matched sentences  \n",
    "- **Average similarity**: Mean semantic similarity across all sentence pairs\n",
    "- **Document-level scores**: Combined similarity metrics for comprehensive consistency assessment\n",
    "\n",
    "This analysis reveals whether companies meaningfully update their environmental narratives or rely on template-based reporting across years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395af05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy_layout import spaCyLayout\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load model\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# Increase max_length to safely handle long texts\n",
    "nlp.max_length = 1_500_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2128fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "report_names = [ \n",
    "    \"Akenerji_Elektrik_Uretim_AS\",\n",
    "    \"Arendals_Fossekompani_ASA\",\n",
    "    \"Atlantica_Sustainable_Infrastructure_PLC\",\n",
    "    \"CEZ\",\n",
    "    \"EDF\",\n",
    "    \"EDP_Energias_de_Portugal_SA\",\n",
    "    \"Endesa\",\n",
    "    \"ERG_SpA\",\n",
    "    \"Orsted\",\n",
    "    \"Polska_Grupa_Energetyczna_PGE_SA\",\n",
    "    \"Romande_Energie_Holding_SA\",\n",
    "    \"Scatec_ASA\",\n",
    "    \"Solaria_Energia_y_Medio_Ambiente_SA\",\n",
    "    \"Terna_Energy_SA\"\n",
    "]\n",
    "\n",
    "folders = {\n",
    "    \"2021\": Path(\"data/NLP/Reports/Cleanest/2021\"),\n",
    "    \"2022\": Path(\"data/NLP/Reports/Cleanest/2022\")\n",
    "}\n",
    "\n",
    "# Check availability\n",
    "for name in report_names:\n",
    "    file_name = f\"{name}.txt\"\n",
    "    in_2021 = (folders[\"2021\"] / file_name).exists()\n",
    "    in_2022 = (folders[\"2022\"] / file_name).exists()\n",
    "    print(f\"{file_name}: 2021: {'YES' if in_2021 else 'NO'} | 2022: {'YES' if in_2022 else 'NO'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a05eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store processed docs\n",
    "documents = {}\n",
    "\n",
    "# Load and process\n",
    "for version, folder_path in folders.items():\n",
    "    for name in report_names:\n",
    "        txt_path = folder_path / f\"{name}.txt\"\n",
    "        try:\n",
    "            with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                text = f.read()\n",
    "            doc_key = f\"{name}_{version}\"\n",
    "            documents[doc_key] = nlp(text)\n",
    "            print(f\"Processed {doc_key}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {txt_path.name}: {e}\")\n",
    "\n",
    "print(f\"\\nTotal documents loaded: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2c41a0",
   "metadata": {},
   "source": [
    "## Doc Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d864231c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# --- TF-IDF document-level similarity ---\n",
    "def tfidf_doc_similarity(doc1, doc2):\n",
    "    \"\"\"\n",
    "    Compute cosine similarity between two documents using TF-IDF vectorization.\n",
    "    Lemmatizes and filters tokens before vectorizing full documents.\n",
    "    Source: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "    \"\"\"\n",
    "    def clean_text(doc):\n",
    "        return \" \".join([\n",
    "            token.lemma_.lower() \n",
    "            for token in doc \n",
    "            if not token.is_stop and not token.is_punct and token.is_alpha\n",
    "        ])\n",
    "    \n",
    "    # Preprocess documents\n",
    "    text1 = clean_text(doc1)\n",
    "    text2 = clean_text(doc2)\n",
    "    \n",
    "    # Vectorize using TF-IDF (word- and phrase-level)\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        max_features=4000,       # Limit vocabulary for speed\n",
    "        ngram_range=(1, 3),      # Use unigrams, bigrams, trigrams\n",
    "        norm='l2'                # Normalize vectors for cosine similarity\n",
    "    )\n",
    "    tfidf_matrix = vectorizer.fit_transform([text1, text2])\n",
    "    \n",
    "    # Calculate cosine similarity between the two document vectors\n",
    "    similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]\n",
    "    return similarity\n",
    "\n",
    "# --- Jaccard similarity ---\n",
    "def jaccard_similarity(doc1, doc2):\n",
    "    \"\"\"\n",
    "    Compute Jaccard similarity between sets of unique lemmatized words.\n",
    "    Measures overlap in vocabulary between two documents.\n",
    "    Source: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.jaccard_score.html\n",
    "    \"\"\"\n",
    "    words1 = {token.lemma_.lower() for token in doc1 if not token.is_stop and not token.is_punct and token.is_alpha}\n",
    "    words2 = {token.lemma_.lower() for token in doc2 if not token.is_stop and not token.is_punct and token.is_alpha}\n",
    "    \n",
    "    intersection = len(words1 & words2)\n",
    "    union = len(words1 | words2)\n",
    "    \n",
    "    return intersection / union if union else 0\n",
    "\n",
    "def spacy_sentence_similarity(doc1, doc2, threshold=0.999):\n",
    "    \"\"\"\n",
    "    Compare sentences between two documents using spaCy's built-in similarity with greedy matching.\n",
    "    \n",
    "    Args:\n",
    "        doc1: spaCy Doc object for 2021 document\n",
    "        doc2: spaCy Doc object for 2022 document  \n",
    "        threshold: Similarity threshold for high similarity ratio\n",
    "    \n",
    "    Returns:\n",
    "        dict: Contains high_similarity_ratio, matched_pairs, and similarity_scores\n",
    "\n",
    "    Source: https://spacy.io/usage/linguistic-features#vectors-similarity\n",
    "    \"\"\"\n",
    "    \n",
    "    def filter_sentences(doc):\n",
    "        \"\"\"Filter sentences with more than 10 lemmatized words (excluding stopwords/punctuation)\"\"\"\n",
    "        filtered_sentences = []\n",
    "        \n",
    "        for sent in doc.sents:\n",
    "            # Count lemmatized words excluding stopwords and punctuation\n",
    "            lemmatized_words = [\n",
    "                token.lemma_.lower() \n",
    "                for token in sent \n",
    "                if not token.is_stop and not token.is_punct and token.is_alpha\n",
    "            ]\n",
    "            \n",
    "            # Only include sentences with more than 10 such words\n",
    "            if len(lemmatized_words) > 10:\n",
    "                filtered_sentences.append(sent)\n",
    "        \n",
    "        return filtered_sentences\n",
    "    \n",
    "    # Step 1: Filter sentences from both documents\n",
    "    sentences_2021 = filter_sentences(doc1)\n",
    "    sentences_2022 = filter_sentences(doc2)\n",
    "    \n",
    "    print(f\"Filtered sentences - 2021: {len(sentences_2021)}, 2022: {len(sentences_2022)}\")\n",
    "    \n",
    "    if not sentences_2021 or not sentences_2022:\n",
    "        return {\n",
    "            'high_similarity_ratio': 0.0,\n",
    "            'avg_similarity': 0.0,\n",
    "            'matched_pairs': [],\n",
    "            'similarity_scores': []\n",
    "        }\n",
    "    \n",
    "    # Step 2 & 3: Greedy matching process\n",
    "    matched_pairs = []\n",
    "    similarity_scores = []\n",
    "    \n",
    "    # Create working copies of sentence lists\n",
    "    remaining_2021 = sentences_2021.copy()\n",
    "    remaining_2022 = sentences_2022.copy()\n",
    "    \n",
    "    while remaining_2021 and remaining_2022:\n",
    "        # Compute similarity matrix for remaining sentences\n",
    "        similarity_matrix = []\n",
    "        max_similarity = -1\n",
    "        best_pairs = []\n",
    "        \n",
    "        # Find all sentence pairs and their similarities\n",
    "        for i, sent_2021 in enumerate(remaining_2021):\n",
    "            row = []\n",
    "            for j, sent_2022 in enumerate(remaining_2022):\n",
    "                similarity = sent_2021.similarity(sent_2022)\n",
    "                row.append(similarity)\n",
    "                \n",
    "                # Track the highest similarity score(s)\n",
    "                if similarity > max_similarity:\n",
    "                    max_similarity = similarity\n",
    "                    best_pairs = [(i, j, similarity)]\n",
    "                elif similarity == max_similarity:\n",
    "                    best_pairs.append((i, j, similarity))\n",
    "            \n",
    "            similarity_matrix.append(row)\n",
    "        \n",
    "        if max_similarity == -1:  # No valid similarities computed\n",
    "            break\n",
    "            \n",
    "        # Handle ties: select pairs that refer to unique sentences\n",
    "        selected_pairs = []\n",
    "        used_2021_indices = set()\n",
    "        used_2022_indices = set()\n",
    "        \n",
    "        for i, j, sim in best_pairs:\n",
    "            if i not in used_2021_indices and j not in used_2022_indices:\n",
    "                selected_pairs.append((i, j, sim))\n",
    "                used_2021_indices.add(i)\n",
    "                used_2022_indices.add(j)\n",
    "        \n",
    "        # Add selected pairs to results\n",
    "        for i, j, sim in selected_pairs:\n",
    "            matched_pairs.append((remaining_2021[i], remaining_2022[j]))\n",
    "            similarity_scores.append(sim)\n",
    "        \n",
    "        # Remove selected sentences from remaining lists (in reverse order to maintain indices)\n",
    "        indices_2021_to_remove = sorted([i for i, j, sim in selected_pairs], reverse=True)\n",
    "        indices_2022_to_remove = sorted([j for i, j, sim in selected_pairs], reverse=True)\n",
    "        \n",
    "        for idx in indices_2021_to_remove:\n",
    "            remaining_2021.pop(idx)\n",
    "        for idx in indices_2022_to_remove:\n",
    "            remaining_2022.pop(idx)\n",
    "    \n",
    "    # Step 4: Calculate high similarity ratio and average similarity\n",
    "    if not similarity_scores:\n",
    "        high_similarity_ratio = 0.0\n",
    "        avg_similarity = 0.0\n",
    "    else:\n",
    "        high_similarity_count = sum(1 for score in similarity_scores if score > threshold)\n",
    "        high_similarity_ratio = high_similarity_count / len(similarity_scores)\n",
    "        avg_similarity = np.mean(similarity_scores)\n",
    "\n",
    "    print(f\"Matched pairs: {len(matched_pairs)}\")\n",
    "    print(f\"High similarity pairs (>{threshold}): {sum(1 for score in similarity_scores if score > threshold)}\")\n",
    "    print(f\"High similarity ratio: {high_similarity_ratio:.4f}\")\n",
    "    print(f\"Average similarity: {avg_similarity:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'high_similarity_ratio': high_similarity_ratio,\n",
    "        'avg_similarity': avg_similarity,\n",
    "        'matched_pairs': matched_pairs,\n",
    "        'similarity_scores': similarity_scores\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c513d069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")  # Nice color palette\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Create output directories\n",
    "results_dir = Path(\"data/NLP/Results\")\n",
    "similarity_dir = results_dir / \"Similarity\"\n",
    "figures_dir = results_dir / \"Figures\" / \"Similarity\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "similarity_dir.mkdir(parents=True, exist_ok=True)\n",
    "figures_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Initialize results list and similarity scores storage\n",
    "results = []\n",
    "company_similarity_scores = {}  # Store similarity scores for histograms\n",
    "\n",
    "# Modified results collection loop\n",
    "for company in report_names:\n",
    "    key_2021 = f\"{company}_2021\"\n",
    "    key_2022 = f\"{company}_2022\"\n",
    "    \n",
    "    if key_2021 in documents and key_2022 in documents:\n",
    "        print(f\"\\nAnalyzing {company}...\")\n",
    "\n",
    "        # Retrieve SpaCy Docs\n",
    "        doc1 = documents[key_2021]\n",
    "        doc2 = documents[key_2022]\n",
    "\n",
    "        # Document-level similarity scores\n",
    "        print(\"  Computing TF-IDF similarity...\")\n",
    "        tfidf_score = tfidf_doc_similarity(doc1, doc2)\n",
    "        \n",
    "        print(\"  Computing Jaccard similarity...\")\n",
    "        jaccard_score = jaccard_similarity(doc1, doc2)\n",
    "        \n",
    "        # Sentence-level similarity using spaCy\n",
    "        print(\"  Computing sentence-level similarity...\")\n",
    "        sentence_similarity_result = spacy_sentence_similarity(doc1, doc2)\n",
    "        high_sim_ratio = sentence_similarity_result['high_similarity_ratio']\n",
    "        avg_sim = sentence_similarity_result['avg_similarity']\n",
    "        \n",
    "        # Store similarity scores for histogram\n",
    "        similarity_scores = sentence_similarity_result['similarity_scores']\n",
    "        if similarity_scores:  # Only store if we have scores\n",
    "            company_similarity_scores[company] = similarity_scores\n",
    "\n",
    "        # Append results to list (updated with new metrics)\n",
    "        results.append({\n",
    "            'Company': company.replace(\"_\", \" \"),\n",
    "            'TFIDF_Doc': tfidf_score,\n",
    "            'Jaccard': jaccard_score,\n",
    "            'SpaCy_HighSim_Ratio': high_sim_ratio,\n",
    "            'SpaCy_Avg_Similarity': avg_sim,\n",
    "            'Num_Sentence_Pairs': len(similarity_scores)\n",
    "        })\n",
    "        \n",
    "        print(f\"Complete - {len(similarity_scores)} sentence pairs analyzed\")\n",
    "\n",
    "# Convert results to DataFrame for analysis or export\n",
    "df_similarity = pd.DataFrame(results).round(4)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SIMILARITY SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(df_similarity.to_string(index=False))\n",
    "\n",
    "# Save DataFrame to Excel\n",
    "excel_path = similarity_dir / \"similarity_analysis_results.xlsx\"\n",
    "print(f\"\\nSaving results to Excel: {excel_path}\")\n",
    "\n",
    "with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
    "    # Main results sheet\n",
    "    df_similarity.to_excel(writer, sheet_name='Similarity_Results', index=False)\n",
    "    \n",
    "    # Summary statistics sheet\n",
    "    summary_stats = df_similarity.describe()\n",
    "    summary_stats.to_excel(writer, sheet_name='Summary_Statistics')\n",
    "    \n",
    "    # Individual company sentence scores (if available)\n",
    "    if company_similarity_scores:\n",
    "        # Create a sheet with all similarity scores\n",
    "        all_scores_data = []\n",
    "        for company, scores in company_similarity_scores.items():\n",
    "            for score in scores:\n",
    "                all_scores_data.append({\n",
    "                    'Company': company.replace(\"_\", \" \"),\n",
    "                    'Similarity_Score': score\n",
    "                })\n",
    "        \n",
    "        df_all_scores = pd.DataFrame(all_scores_data)\n",
    "        df_all_scores.to_excel(writer, sheet_name='All_Sentence_Similarities', index=False)\n",
    "\n",
    "print(f\"Excel file saved successfully!\")\n",
    "\n",
    "# Create histograms for each company\n",
    "print(f\"\\nCreating histograms for similarity scores...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Define colors for companies (using seaborn color palette)\n",
    "colors = sns.color_palette(\"husl\", len(company_similarity_scores))\n",
    "company_colors = dict(zip(company_similarity_scores.keys(), colors))\n",
    "\n",
    "for i, (company, scores) in enumerate(company_similarity_scores.items()):\n",
    "    if not scores:  # Skip if no scores\n",
    "        continue\n",
    "        \n",
    "    print(f\"Creating histogram for {company.replace('_', ' ')}...\")\n",
    "    \n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Create histogram\n",
    "    n_bins = min(30, len(scores) // 2)  # Adaptive number of bins\n",
    "    n_bins = max(10, n_bins)  # Ensure minimum 10 bins\n",
    "    \n",
    "    counts, bins, patches = ax.hist(\n",
    "        scores, \n",
    "        bins=n_bins, \n",
    "        alpha=0.7, \n",
    "        color=company_colors[company],\n",
    "        edgecolor='black',\n",
    "        linewidth=0.5\n",
    "    )\n",
    "    \n",
    "    # Customize the plot\n",
    "    company_display_name = company.replace(\"_\", \" \")\n",
    "    ax.set_title(f'Sentence Similarity Score Distribution\\n{company_display_name}', \n",
    "                fontsize=16, fontweight='bold', pad=20)\n",
    "    ax.set_xlabel('Similarity Score', fontsize=14)\n",
    "    ax.set_ylabel('Frequency', fontsize=14)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add statistics text box\n",
    "    mean_score = np.mean(scores)\n",
    "    median_score = np.median(scores)\n",
    "    std_score = np.std(scores)\n",
    "    min_score = np.min(scores)\n",
    "    max_score = np.max(scores)\n",
    "    \n",
    "    stats_text = f'Statistics:\\n' \\\n",
    "                f'Mean: {mean_score:.3f}\\n' \\\n",
    "                f'Median: {median_score:.3f}\\n' \\\n",
    "                f'Std Dev: {std_score:.3f}\\n' \\\n",
    "                f'Min: {min_score:.3f}\\n' \\\n",
    "                f'Max: {max_score:.3f}\\n' \\\n",
    "                f'N: {len(scores)}'\n",
    "    \n",
    "    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, \n",
    "            verticalalignment='top', horizontalalignment='left',\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n",
    "            fontsize=11)\n",
    "    \n",
    "    # Add vertical line for mean\n",
    "    ax.axvline(mean_score, color='red', linestyle='--', linewidth=2, \n",
    "               label=f'Mean: {mean_score:.3f}')\n",
    "    ax.legend()\n",
    "    \n",
    "    # Set x-axis limits\n",
    "    ax.set_xlim(0, 1)\n",
    "    \n",
    "    # Improve layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the figure\n",
    "    company_dir = figures_dir / company\n",
    "    company_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    filename = f\"{company}_similarity_histogram.png\"\n",
    "    filepath = company_dir / filename\n",
    "    \n",
    "    plt.savefig(filepath, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    print(f\"Saved: {filepath}\")\n",
    "    \n",
    "    # Also save as PDF for better quality\n",
    "    pdf_filepath = company_dir / f\"{company}_similarity_histogram.pdf\"\n",
    "    plt.savefig(pdf_filepath, bbox_inches='tight', facecolor='white')\n",
    "    \n",
    "    plt.close()  # Close the figure to free memory\n",
    "\n",
    "# Create a combined overview plot\n",
    "if len(company_similarity_scores) > 1:\n",
    "    print(\"\\nCreating combined overview plot...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=(len(company_similarity_scores) + 2) // 3,  # 3 columns\n",
    "        ncols=3,\n",
    "        figsize=(18, 6 * ((len(company_similarity_scores) + 2) // 3))\n",
    "    )\n",
    "    \n",
    "    # Flatten axes array for easy indexing\n",
    "    if len(company_similarity_scores) > 3:\n",
    "        axes = axes.flatten()\n",
    "    elif len(company_similarity_scores) > 1:\n",
    "        axes = [axes] if len(company_similarity_scores) == 1 else axes.flatten()\n",
    "    else:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, (company, scores) in enumerate(company_similarity_scores.items()):\n",
    "        if i >= len(axes):\n",
    "            break\n",
    "            \n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Create mini histogram\n",
    "        n_bins = min(20, len(scores) // 2)\n",
    "        n_bins = max(8, n_bins)\n",
    "        \n",
    "        ax.hist(scores, bins=n_bins, alpha=0.7, \n",
    "                color=company_colors[company], edgecolor='black', linewidth=0.3)\n",
    "        \n",
    "        # Customize\n",
    "        company_name = company.replace(\"_\", \" \")\n",
    "        ax.set_title(company_name, fontsize=12, fontweight='bold')\n",
    "        ax.set_xlabel('Similarity Score', fontsize=10)\n",
    "        ax.set_ylabel('Frequency', fontsize=10)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_xlim(0, 1)\n",
    "        \n",
    "        # Add mean line\n",
    "        mean_score = np.mean(scores)\n",
    "        ax.axvline(mean_score, color='red', linestyle='--', linewidth=1.5)\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].set_visible(False)\n",
    "    \n",
    "    plt.suptitle('Sentence Similarity Score Distributions - All Companies', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save combined plot\n",
    "    combined_path = figures_dir / \"combined_similarity_histograms.png\"\n",
    "    plt.savefig(combined_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    print(f\"Combined plot saved: {combined_path}\")\n",
    "    \n",
    "    plt.close()\n",
    "\n",
    "# Print final summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Results saved to Excel: {excel_path}\")\n",
    "print(f\"Individual histograms saved to: {figures_dir}\")\n",
    "print(f\"Companies processed: {len(company_similarity_scores)}\")\n",
    "print(f\"Total sentence pairs analyzed: {sum(len(scores) for scores in company_similarity_scores.values())}\")\n",
    "\n",
    "# Display final DataFrame\n",
    "print(f\"\\nFinal Results Summary:\")\n",
    "print(\"-\" * 50)\n",
    "print(df_similarity.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4855440b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show examples of sentence pairs across different similarity ranges\n",
    "print(\"\\nSENTENCE SIMILARITY ANALYSIS - EXAMPLES ACROSS RANGES\")\n",
    "print(\"=\" * 75)\n",
    "print(\"Showing sentence pairs across different similarity levels\")\n",
    "print(\"High similarity (≥0.999), Medium similarity, Low similarity\")\n",
    "print()\n",
    "\n",
    "# Function to find sentence pairs in specific similarity ranges\n",
    "def get_similarity_examples_by_range(company_name, doc1, doc2):\n",
    "    \"\"\"Extract sentence pairs across different similarity ranges\"\"\"\n",
    "    \n",
    "    def filter_sentences(doc):\n",
    "        \"\"\"Filter sentences with more than 10 lemmatized words (excluding stopwords/punctuation)\"\"\"\n",
    "        filtered_sentences = []\n",
    "        \n",
    "        for sent in doc.sents:\n",
    "            lemmatized_words = [\n",
    "                token.lemma_.lower() \n",
    "                for token in sent \n",
    "                if not token.is_stop and not token.is_punct and token.is_alpha\n",
    "            ]\n",
    "            \n",
    "            if len(lemmatized_words) > 10:\n",
    "                filtered_sentences.append(sent)\n",
    "        \n",
    "        return filtered_sentences\n",
    "    \n",
    "    # Filter sentences from both documents\n",
    "    sentences_2021 = filter_sentences(doc1)\n",
    "    sentences_2022 = filter_sentences(doc2)\n",
    "    \n",
    "    if not sentences_2021 or not sentences_2022:\n",
    "        return {}\n",
    "    \n",
    "    # Create a smaller sample if documents are very large (for performance)\n",
    "    max_sentences = 300  # Limit to prevent excessive computation\n",
    "    if len(sentences_2021) > max_sentences:\n",
    "        sentences_2021 = sentences_2021[:max_sentences]\n",
    "    if len(sentences_2022) > max_sentences:\n",
    "        sentences_2022 = sentences_2022[:max_sentences]\n",
    "    \n",
    "    # Define similarity ranges\n",
    "    similarity_ranges = {\n",
    "        'high': {'min': 0.999, 'max': 0.99999999, 'pairs': []},      # 0.999 - 1.000\n",
    "        'medium_high': {'min': 0.9, 'max': 0.95, 'pairs': []}, # ~0.925\n",
    "        'medium': {'min': 0.85, 'max': 0.9, 'pairs': []},      # ~0.875  \n",
    "        'low': {'min': 0.45, 'max': 0.55, 'pairs': []}          # ~0.5\n",
    "    }\n",
    "    \n",
    "    print(f\"Analyzing {len(sentences_2021)} sentences from 2021 vs {len(sentences_2022)} sentences from 2022...\")\n",
    "    \n",
    "    # Compare sentence pairs and categorize by similarity\n",
    "    pairs_checked = 0\n",
    "    for i, sent_2021 in enumerate(sentences_2021):\n",
    "        for j, sent_2022 in enumerate(sentences_2022):\n",
    "            try:\n",
    "                similarity = sent_2021.similarity(sent_2022)\n",
    "                pairs_checked += 1\n",
    "                \n",
    "                # Check which range this similarity falls into\n",
    "                for range_name, range_info in similarity_ranges.items():\n",
    "                    if range_info['min'] <= similarity <= range_info['max']:\n",
    "                        range_info['pairs'].append({\n",
    "                            'similarity': similarity,\n",
    "                            'sentence_2021': sent_2021.text.strip(),\n",
    "                            'sentence_2022': sent_2022.text.strip()\n",
    "                        })\n",
    "                        break\n",
    "                \n",
    "                # Stop early if we have enough examples in each category\n",
    "                if all(len(range_info['pairs']) >= 5 for range_info in similarity_ranges.values()):\n",
    "                    break\n",
    "                    \n",
    "            except:\n",
    "                continue  # Skip if similarity computation fails\n",
    "        \n",
    "        # Break outer loop if we have enough examples\n",
    "        if all(len(range_info['pairs']) >= 5 for range_info in similarity_ranges.values()):\n",
    "            break\n",
    "    \n",
    "    print(f\"Checked {pairs_checked} sentence pairs\")\n",
    "    return similarity_ranges\n",
    "\n",
    "# Find the company being analyzed (assumes only one company in documents)\n",
    "company_name = None\n",
    "available_companies = set()\n",
    "\n",
    "for doc_key in documents.keys():\n",
    "    if doc_key.endswith('_2021') or doc_key.endswith('_2022'):\n",
    "        company = doc_key.replace('_2021', '').replace('_2022', '')\n",
    "        available_companies.add(company)\n",
    "\n",
    "if len(available_companies) == 1:\n",
    "    company_name = list(available_companies)[0]\n",
    "elif len(available_companies) > 1:\n",
    "    # If multiple companies, take the first one\n",
    "    company_name = sorted(list(available_companies))[0]\n",
    "    print(f\"Multiple companies found, analyzing: {company_name.replace('_', ' ')}\")\n",
    "\n",
    "if company_name:\n",
    "    key_2021 = f\"{company_name}_2021\"\n",
    "    key_2022 = f\"{company_name}_2022\"\n",
    "    \n",
    "    if key_2021 in documents and key_2022 in documents:\n",
    "        print(f\"ANALYZING COMPANY: {company_name.replace('_', ' ')}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        doc1 = documents[key_2021]\n",
    "        doc2 = documents[key_2022]\n",
    "        \n",
    "        # Get examples across similarity ranges\n",
    "        similarity_ranges = get_similarity_examples_by_range(company_name, doc1, doc2)\n",
    "        \n",
    "        # Display examples for each range\n",
    "        range_descriptions = {\n",
    "            'high': 'HIGH SIMILARITY (0.999 - 1.000) - Near identical/identical content',\n",
    "            'medium_high': 'MEDIUM-HIGH SIMILARITY (~0.95)',\n",
    "            'medium': 'MEDIUM SIMILARITY (~0.9)', \n",
    "            'low': 'LOW SIMILARITY (~0.5)'\n",
    "        }\n",
    "        \n",
    "        for range_name, description in range_descriptions.items():\n",
    "            range_data = similarity_ranges[range_name]\n",
    "            pairs = range_data['pairs']\n",
    "            \n",
    "            print(f\"\\n{description}\")\n",
    "            print(\"=\" * 75)\n",
    "            \n",
    "            if pairs:\n",
    "                # Sort by similarity score (highest first) and show top examples\n",
    "                pairs.sort(key=lambda x: x['similarity'], reverse=True)\n",
    "                examples_to_show = min(3, len(pairs))  # Show up to 3 examples per range\n",
    "                \n",
    "                print(f\"Found {len(pairs)} pairs in this range. Showing top {examples_to_show}:\")\n",
    "                print()\n",
    "                \n",
    "                for i, pair in enumerate(pairs[:examples_to_show], 1):\n",
    "                    similarity = pair['similarity']\n",
    "                    sent_2021 = pair['sentence_2021']\n",
    "                    sent_2022 = pair['sentence_2022']\n",
    "                    \n",
    "                    # Truncate very long sentences for display\n",
    "                    max_length = 250\n",
    "                    if len(sent_2021) > max_length:\n",
    "                        sent_2021 = sent_2021[:max_length] + \"...\"\n",
    "                    if len(sent_2022) > max_length:\n",
    "                        sent_2022 = sent_2022[:max_length] + \"...\"\n",
    "                    \n",
    "                    print(f\"EXAMPLE {i} - SIMILARITY: {similarity:.6f}\")\n",
    "                    print(f\"2021: {sent_2021}\")\n",
    "                    print(f\"2022: {sent_2022}\")\n",
    "                    print(\"-\" * 75)\n",
    "            else:\n",
    "                print(\"No sentence pairs found in this similarity range.\")\n",
    "                print(\"Try expanding the similarity range or checking more sentence pairs.\")\n",
    "                print()\n",
    "        \n",
    "        # Summary statistics\n",
    "        total_pairs_found = sum(len(range_data['pairs']) for range_data in similarity_ranges.values())\n",
    "        print(f\"\\nSUMMARY:\")\n",
    "        print(f\"Total examples found across all ranges: {total_pairs_found}\")\n",
    "        for range_name, description in range_descriptions.items():\n",
    "            count = len(similarity_ranges[range_name]['pairs'])\n",
    "            range_min = similarity_ranges[range_name]['min']\n",
    "            range_max = similarity_ranges[range_name]['max']\n",
    "            print(f\"  {range_name.replace('_', '-').title()}: {count} pairs ({range_min:.3f} - {range_max:.3f})\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"Documents not found for {company_name}\")\n",
    "        print(f\"Available document keys: {list(documents.keys())}\")\n",
    "\n",
    "else:\n",
    "    print(\"No company documents found in the expected format.\")\n",
    "    print(\"Expected format: CompanyName_2021, CompanyName_2022\")\n",
    "    print(f\"Available document keys: {list(documents.keys())}\")\n",
    "\n",
    "print(f\"\\nSimilarity range analysis complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
